%Universal Training Script
%20201103 build
%20201105 add ten folding section
function [net,options,traininfo,result] = uniTrain(params,digitDatasetPath)
%%
oldimds = imageDatastore(digitDatasetPath, ...
    'IncludeSubfolders',true, ...
    'LabelSource','foldernames');
%%
if params.foldNo == 1
    [TestSet,TrainSet] = splitEachLabel(oldimds,0.1,0.9);
else
    [TrainSet,subds{2:10}]=splitEachLabel(oldimds,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1,0.1);
    for i = 2:10
        if( i == params.foldNo)
            TestSet = subds{i};
        else
            imdTemp = imageDatastore(cat(1,TrainSet.Files,subds{i}.Files));
            imdTemp.Labels = (cat(1,TrainSet.Labels,subds{i}.Labels));
            TrainSet = imdTemp;
        end
    end
    clear imdTemp;
end
[TrainSet,DevSet] = splitEachLabel(TrainSet,0.7,0.3);
%%
categ = categories(TrainSet.Labels);
fprintf("%20s            | %9s | %9s\n","ROA","Amount","Percentage")
for i = 1:length(categ)
    fprintf("   %-30s|%10d|%10.2f%% \n",categ{i},sum(TrainSet.Labels==categ{i}),sum(TrainSet.Labels==categ{i})/length(TrainSet.Files)*100);
end
TrainSet = shuffle(TrainSet);
DevSet = shuffle(DevSet);
TestSet = shuffle(TestSet);
clear oldimds;
numClasses = numel(categories(TrainSet.Labels));
TrainSet = augmentedImageDatastore([224 224],TrainSet, ...
    'ColorPreprocessing','gray2rgb');
DevSet = augmentedImageDatastore([224 224],DevSet, ...
    'ColorPreprocessing','gray2rgb');
disp('Data preprocess finished');
%%
% layers = layerGraph(googlenet);
% layers = googlenet('Weights','none');
layers = resnet18('Weights','none');
newLearnableLayer = fullyConnectedLayer(numClasses, ...
    'Name','new_fc', ...
    'WeightLearnRateFactor',params.WeightLearnRateFactor, ...
    'BiasLearnRateFactor',params.BiasLearnRateFactor);
newClassLayer = classificationLayer('Name','new_classoutput');
layers = replaceLayer(layers,'fc1000',newLearnableLayer); %resnet50„ÄÅresnet18
% layers = replaceLayer(layers,'ClassificationLayer_fc1000',newClassLayer); %resnet50
layers = replaceLayer(layers,'ClassificationLayer_predictions',newClassLayer); %resnet18
% layers = replaceLayer(layers,'loss3-classifier',newLearnableLayer);
% layers = replaceLayer(layers,'output',newClassLayer);
%options = defaultOptions();

switch params.optionType
    case 0
        options = trainingOptions('sgdm', ...
            'MaxEpochs',15, ...
            'ValidationData',DevSet, ...
            'ValidationFrequency',10, ...
            'InitialLearnRate',0.1,...
            "MiniBatchSize",75,...
            'ValidationPatience',40,...
            "Shuffle","every-epoch",...
            "Plots","training-progress");
    case 1
        options = trainingOptions('sgdm', ...
            'MaxEpochs',10, ...
            'ValidationData',DevSet, ...
            'ValidationFrequency',10, ...
            'InitialLearnRate',params.myInitialLearnRate,...
            'VerboseFrequency',5,...
            'ValidationPatience',inf,...
            "MiniBatchSize",128,...
            "Shuffle","every-epoch",...
            "Plots","training-progress",...
            "L2Regularization",params.L2Re);
    case 2
        options = trainingOptions('sgdm', ...
            'MaxEpochs',10, ...
            'ValidationData',DevSet, ...
            'ValidationFrequency',15, ...
            'InitialLearnRate',params.myInitialLearnRate,...
            'VerboseFrequency',5,...
            'ValidationPatience',inf,...
            "MiniBatchSize",128,...
            "Shuffle","every-epoch",...
            "Plots","training-progress",...
            "L2Regularization",params.L2Re);
    case 3
        options = trainingOptions('sgdm', ...
            'MaxEpochs',10, ...
            'ValidationData',DevSet, ...
            'ValidationFrequency',10, ...
            'InitialLearnRate',params.myInitialLearnRate,...
            'VerboseFrequency',5,...
            'ValidationPatience',20,...
            "MiniBatchSize",128,...
            "Shuffle","every-epoch",...
            "Plots","training-progress",...
            "LearnRateDropFactor",0.9,...
            "LearnRateDropPeriod",1,...
            "LearnRateSchedule","piecewise",...
            "L2Regularization",params.L2Re);
        %     'LearnRateSchedule','piecewise',...
        %             'LearnRateDropPeriod',1,...
        %             'LearnRateDropFactor',0.5,...
end
disp('Network and options created');
disp("Fold no."+params.foldNo);
%%
[net, traininfo] = trainNetwork(TrainSet,layers,options);
%%
result = Mclassify(net,[224 224],1,TestSet);
end